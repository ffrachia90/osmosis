---
description: LLM: IntegraciÃ³n con Claude 3.5 Sonnet
globs: src/core/llm/*
alwaysApply: true
---
# LLMSERVICE - IntegraciÃ³n con Claude 3.5 Sonnet

## UBICACIÃ“N

`src/core/llm/LLMService.ts`

---

## CONFIGURACIÃ“N

### Constructor
```typescript
const llm = new LLMService({
  apiKey: process.env.ANTHROPIC_API_KEY,  // OBLIGATORIA
  model: 'claude-3-5-sonnet-20241022',    // Default
  maxTokens: 8000,                         // Default
  temperature: 0.7,                        // Default
  baseURL: 'https://api.anthropic.com'    // Opcional: para proxy
});
```

### Variables de Entorno
```bash
# OBLIGATORIA - Sin esto Osmosis no funciona
export ANTHROPIC_API_KEY="sk-ant-api03-..."

# OPCIONAL - Para empresas con proxy corporativo
export ANTHROPIC_BASE_URL="https://llm-proxy.company.com"
```

---

## MÃ‰TODOS PRINCIPALES

### 1. `generate(prompt)` - Sin Streaming

```typescript
const code = await llm.generate(prompt);
```

- MÃ¡s rÃ¡pido para batch processing
- Sin feedback visual
- Retorna string completo

---

### 2. `generateWithStreaming(prompt, callbacks)` - Con Streaming

```typescript
const code = await llm.generateWithStreaming(prompt, {
  onStart: () => {
    console.log('ğŸ¤– Generando...');
  },
  onToken: (token: string) => {
    process.stdout.write(token); // Streaming en tiempo real
  },
  onComplete: (fullText: string) => {
    console.log('\nâœ… GeneraciÃ³n completa');
  },
  onError: (error: Error) => {
    console.error('âŒ Error:', error.message);
  }
});
```

**Output en Terminal**:
```
ğŸ¤– Generando...
import React from 'react';

export const LoginForm: React.FC = () => {
  const [email, setEmail] = useState('');
  ...
âœ… GeneraciÃ³n completa
```

---

### 3. `repair(code, errors, framework, attempt)` - Auto-ReparaciÃ³n

```typescript
const repairedCode = await llm.repair(
  originalCode,
  [
    'Class Component detected',
    'dangerouslySetInnerHTML without sanitization',
    'Missing alt attribute'
  ],
  'react',
  attempt: 1  // 1, 2, o 3
);
```

**Prompt Generado AutomÃ¡ticamente**:
```markdown
# ğŸ”§ CODE REPAIR - Attempt 1/3

## âŒ Validation Errors Detected
1. Class Component detected
2. dangerouslySetInnerHTML without sanitization
3. Missing alt attribute

## ğŸ› Problematic Code
```tsx
class LoginForm extends React.Component { ... }
```

## âœ… Your Task
1. Fix ALL errors listed above
2. Maintain the original functionality
3. Keep the same component structure
4. Use modern best practices
5. Return ONLY the fixed code

## ğŸ¯ Common Fixes
- Class Components â†’ Functional Components + Hooks
- dangerouslySetInnerHTML â†’ Use DOMPurify
- Missing alt â†’ Add descriptive alt text
```

---

### 4. `healthCheck()` - Verificar ConexiÃ³n

```typescript
const isHealthy = await llm.healthCheck();

if (!isHealthy) {
  console.error('âŒ No se pudo conectar con Claude');
  process.exit(1);
}
```

---

## FLUJO DE MIGRACIÃ“N CON AUTO-REPARACIÃ“N

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Generar CÃ³digo (Primera Vez)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PromptAssembler.assemble()                  â”‚
â”‚   â†“                                          â”‚
â”‚ ContextInjector.enrichPrompt() (RAG)        â”‚
â”‚   â†“                                          â”‚
â”‚ LLMService.generateWithStreaming()          â”‚
â”‚   â†“                                          â”‚
â”‚ CÃ³digo Generado                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. ValidaciÃ³n con CodeSafeGuard             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ CodeSafeGuard.validate(code)                â”‚
â”‚   â†“                                          â”‚
â”‚ âœ… Valid?  â†’ Guardar y continuar            â”‚
â”‚ âŒ Invalid? â†’ Ir a Auto-ReparaciÃ³n          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Auto-ReparaciÃ³n (Max 3 Intentos)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Loop while attempts < 3:                    â”‚
â”‚   LLMService.repair(code, errors, framework)â”‚
â”‚   CodeSafeGuard.validate(repairedCode)      â”‚
â”‚   if valid â†’ break                          â”‚
â”‚                                              â”‚
â”‚ Si falla 3 veces â†’ Fallback (fixes known)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## CONFIGURACIÃ“N AVANZADA

### Temperature

Controla la creatividad del LLM:

| Valor | Uso | Comportamiento |
|-------|-----|----------------|
| 0.3 | Reparaciones | Determinista, evita nuevos errores |
| 0.7 | Default | Balanceado |
| 1.0 | Nuevas features | MÃ¡s creativo |

```typescript
// Para reparaciones: mÃ¡s determinista
const llmRepair = new LLMService({ temperature: 0.3 });

// Para generaciÃ³n inicial: balanceado
const llmGenerate = new LLMService({ temperature: 0.7 });
```

### Max Tokens

Controla el tamaÃ±o mÃ¡ximo de respuesta:

| Valor | Uso | Costo Relativo |
|-------|-----|----------------|
| 4000 | Archivos pequeÃ±os | Bajo |
| 8000 | Default | Medio |
| 16000 | Archivos grandes | Alto |

```typescript
// Archivos grandes
const llm = new LLMService({ maxTokens: 16000 });
```

---

## COSTOS

### Claude 3.5 Sonnet (2025)

| MÃ©trica | Costo |
|---------|-------|
| Input (Prompt) | $3.00 / 1M tokens |
| Output (CÃ³digo) | $15.00 / 1M tokens |

### EstimaciÃ³n por Archivo

| TamaÃ±o | Tokens | Costo |
|--------|--------|-------|
| PequeÃ±o (<100 lÃ­neas) | 500 + 1,000 | ~$0.02 |
| Mediano (100-300 lÃ­neas) | 1,500 + 3,000 | ~$0.05 |
| Grande (>300 lÃ­neas) | 3,000 + 6,000 | ~$0.10 |

### Proyecto TÃ­pico (500 archivos)

| Escenario | Costo Total |
|-----------|-------------|
| Sin auto-repair | ~$25 USD |
| Con auto-repair (20%) | ~$30 USD |
| RAG activo | -15% (reuso) |

---

## PROXY EMPRESARIAL

Para empresas que requieren proxy intermedio:

```bash
export ANTHROPIC_API_KEY="tu-key-empresarial"
export ANTHROPIC_BASE_URL="https://llm-proxy.company.com"
```

El proxy puede:
- âœ… Auditar todas las requests
- âœ… Sanitizar prompts (eliminar datos sensibles)
- âœ… Aplicar rate limiting
- âœ… Cachear respuestas (ahorro de costos)

---

## AIR-GAPPED DEPLOYMENT

Si NO se permiten llamadas externas:

**OpciÃ³n A: Self-Hosted LLM (PrÃ³ximamente)**
```bash
export LLM_PROVIDER="local"
export LLM_MODEL_PATH="/models/codellama-13b"
```

**OpciÃ³n B: Claude Enterprise On-Premise**
```bash
export ANTHROPIC_BASE_URL="https://claude.internal.company.com"
```

---

## MANEJO DE ERRORES

### "ANTHROPIC_API_KEY no configurada"
```bash
export ANTHROPIC_API_KEY="sk-ant-api03-..."
```

### "Rate limit exceeded (429)"
- Esperar 60 segundos y reintentar
- Reducir concurrencia
- Upgradar plan de Anthropic

### "Request timeout"
- Verificar conexiÃ³n a internet
- Verificar proxy empresarial
- Reducir maxTokens

### "LLM service health check failed"
```typescript
const isHealthy = await llm.healthCheck();
if (!isHealthy) {
  // Verificar API key
  // Verificar ANTHROPIC_BASE_URL si usa proxy
  // Verificar conexiÃ³n
}
```

---

## EJEMPLO DE USO COMPLETO

```typescript
import { LLMService } from './core/llm/LLMService';
import { CodeSafeGuard } from './core/safeguard/validator';

async function migrateFile(legacyCode: string) {
  const llm = new LLMService({
    apiKey: process.env.ANTHROPIC_API_KEY!,
    maxTokens: 8000,
    temperature: 0.7
  });
  
  // Health check
  if (!await llm.healthCheck()) {
    throw new Error('No se pudo conectar con Claude');
  }
  
  // Generar cÃ³digo
  const prompt = buildPrompt(legacyCode);
  let generatedCode = await llm.generateWithStreaming(prompt, {
    onStart: () => console.log('ğŸ¤– Generando...'),
    onToken: (t) => process.stdout.write(t),
    onComplete: () => console.log('\nâœ… Listo')
  });
  
  // Validar
  let result = CodeSafeGuard.validate(generatedCode, 'react');
  let attempts = 0;
  
  // Auto-repair si es necesario
  while (!result.isValid && attempts < 3) {
    attempts++;
    console.log(`ğŸ”§ Reparando (intento ${attempts}/3)...`);
    
    generatedCode = await llm.repair(
      generatedCode, 
      result.errors, 
      'react', 
      attempts
    );
    
    result = CodeSafeGuard.validate(generatedCode, 'react');
  }
  
  if (!result.isValid) {
    throw new Error(`No se pudo reparar despuÃ©s de 3 intentos: ${result.errors.join(', ')}`);
  }
  
  return generatedCode;
}
```
